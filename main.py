#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒãƒ³ã‚·ãƒ§ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è‡ªå‹•æŠ•ç¨¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  - é‡‘æ›œ23:00JSTå®Ÿè¡Œ â†’ ç¿Œé€±æœˆæ›œã‹ã‚‰æŠ•ç¨¿
  - URLé‡è¤‡æ’é™¤ãƒ»NOKãƒªãƒˆãƒ©ã‚¤(5å›)ãƒ»90å­—CTAå›ºå®š
"""

import os, base64, datetime, random, re, time, requests, html
from bs4 import BeautifulSoup
import gspread
from google.oauth2.service_account import Credentials

# ------------ 0. å®šæ•° ------------
SPREADSHEET_ID = os.environ["SPREADSHEET_ID"]
CLAUDE_API_KEY = os.environ["CLAUDE_API_KEY"]
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]

MAX_PAGES, POST_COUNT = 3, 14
MAX_RETRY_BASE, MAX_EXTRA_RETRY = 3, 5

HISTORY_SHEET, CANDIDATE_SHEET, POST_SHEET = "ã‚¹ãƒ¬å±¥æ­´", "æŠ•ç¨¿å€™è£œ", "æŠ•ç¨¿äºˆå®š"
BANNED_WORDS = ["æ„å‘³ä¸æ˜","å…±ç”£ä¸»ç¾©","ä¸­å›½äºº","è¡€ç¨","ç³å°¿","æ‚©ã‚€","ã‚¹ã‚±ãƒ™","ä½ä¿—","ãƒˆãƒ©ãƒ–ãƒ«","é…·ã„","åŠ£ç­‰æ„Ÿ"]
CTA = " è©³ã—ãã¯ã“ã¡ã‚‰ğŸ‘‡"; MAX_TITLE_LEN = 90 - len(CTA)

# ------------ 1. Google èªè¨¼ ------------
sa = base64.b64decode(os.environ["GCP_SERVICE_ACCOUNT_B64"])
with open("service_account.json","wb") as f: f.write(sa)
gc = gspread.authorize(Credentials.from_service_account_file("service_account.json",scopes=SCOPES))

# ------------ 2. å…±é€šé–¢æ•° ------------
def contains_banned(words,text): return any(re.search(re.escape(w),text,re.I) for w in words)
def claude_call(prompt,max_tokens):
    res = requests.post("https://api.anthropic.com/v1/messages",
        headers={"x-api-key":CLAUDE_API_KEY,"anthropic-version":"2023-06-01"},
        json={"model":"claude-3-haiku-20240307","temperature":0,"max_tokens":max_tokens,
              "messages":[{"role":"user","content":prompt}]},timeout=45)
    res.raise_for_status(); return res.json()["content"][0]["text"].strip()

# ------------ 3. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ ------------
def fetch_threads() -> list[dict]:
    """
    23åŒºæ¿ã‚’ MAX_PAGES åˆ†ã‚¯ãƒ­ãƒ¼ãƒ«ï¼ˆé‡è¤‡ ID é™¤å¤–ï¼‰ã€‚
    - 403/429 ãŒè¿”ã£ãŸã‚‰æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ 2 å›ã¾ã§å†è©¦è¡Œ
    - ãƒšãƒ¼ã‚¸é–“ã®å¾…æ©Ÿæ™‚é–“ã‚’ 2 ç§’ã«å»¶é•·
    """
    threads, seen_ids = [], set()
    ua = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/124.0.0.0 Safari/537.36"
        )
    }

    for page in range(1, MAX_PAGES + 1):
        url = f"https://www.e-mansion.co.jp/bbs/board/23ku/?page={page}"

        # ---- æœ€å¤§ 3 å›ã¾ã§æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤ ----
        success = False
        for retry in range(3):
            try:
                res = requests.get(url, headers=ua, timeout=30)
                if res.status_code == 200:
                    success = True
                    break
                print(f"â–¶ page{page} status={res.status_code} retry={retry+1}")
            except requests.RequestException as e:
                print(f"â–¶ page{page} error={e} retry={retry+1}")

            time.sleep(2 ** (retry + 1))   # 2s â†’ 4s â†’ 8s

        if not success:
            print(f"â–¶ page{page} å–å¾—å¤±æ•—ã€ã‚¹ã‚­ãƒƒãƒ—")
            continue

        soup = BeautifulSoup(res.text, "html.parser")
        for a in soup.select("a.component_thread_list_item"):
            tid = re.search(r"/thread/(\d+)/", a["href"]).group(1)
            if tid in seen_ids:
                continue
            seen_ids.add(tid)

            count_tag = a.select_one("span.num_of_item")
            title_tag = a.select_one("div.oneliner.title")
            count = int(count_tag.get_text(strip=True)) if count_tag else 0
            title = html.unescape(title_tag.get_text(strip=True)) if title_tag else "ã‚¿ã‚¤ãƒˆãƒ«å–å¾—å¤±æ•—"

            threads.append(
                {"url": f"https://www.e-mansion.co.jp/bbs/thread/{tid}/",
                 "id": tid, "title": title, "count": count})

        time.sleep(2)   # ãƒšãƒ¼ã‚¸é–“ãƒ‡ã‚£ãƒ¬ã‚¤ã‚’ 2 ç§’ã«

    return threads

def fetch_thread_text(url,pages=3):
    tid=re.search(r'/thread/(\d+)/',url).group(1)
    ua={"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    posts=[]
    for p in range(1,pages+1):
        try:
            r=requests.get(f"https://www.e-mansion.co.jp/bbs/thread/{tid}/?page={p}",headers=ua,timeout=15); r.raise_for_status()
            soup=BeautifulSoup(r.text,"html.parser")
            posts += [t.get_text(strip=True) for t in soup.select('p[itemprop="commentText"]')]
        except requests.RequestException: continue
        time.sleep(0.3)
    return "\n".join(posts)

def fetch_true_title(url: str) -> str:
    """
    ã‚¹ãƒ¬ãƒƒãƒ‰è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æ­£å¼ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã€
    ã€ã€å£ã‚³ãƒŸæ²ç¤ºæ¿ã€‘ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¨
    ã€ï½œãƒãƒ³ã‚·ãƒ§ãƒ³å£ã‚³ãƒŸãƒ»è©•åˆ¤ï¼ˆâ€¦ï¼‰ã€ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
    """
    ua = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    try:
        res = requests.get(url, headers=ua, timeout=15)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")

        # <title> ã‚¿ã‚°ã‚’å–å¾—
        raw = soup.title.get_text(strip=True)

        # â‘  å…ˆé ­ã®ã€å£ã‚³ãƒŸæ²ç¤ºæ¿ã€‘ã‚’å‰Šé™¤
        raw = re.sub(r'^ã€å£ã‚³ãƒŸæ²ç¤ºæ¿ã€‘', '', raw)

        # â‘¡ ã€Œï½œãƒãƒ³ã‚·ãƒ§ãƒ³å£ã‚³ãƒŸãƒ»è©•åˆ¤ã€ä»¥é™ã‚’ã‚«ãƒƒãƒˆ
        raw = re.sub(r'ï½œãƒãƒ³ã‚·ãƒ§ãƒ³å£ã‚³ãƒŸãƒ»è©•åˆ¤.*$', '', raw)

        return raw.strip()
    except Exception:
        return ""

# ------------ 4. Sheet util ------------
def load_history():
    rows=gc.open_by_key(SPREADSHEET_ID).worksheet(HISTORY_SHEET).get_all_values()[1:]
    return {r[0]:int(r[1]) for r in rows if len(r)>1 and r[1].isdigit()}
def save_history(hist):
    ws=gc.open_by_key(SPREADSHEET_ID).worksheet(HISTORY_SHEET)
    ws.clear(); ws.append_row(["URL","å–å¾—æ™‚ãƒ¬ã‚¹æ•°","æœ€çµ‚å–å¾—æ—¥"])
    ws.append_rows([[u,c,datetime.date.today().isoformat()] for u,c in hist.items()])

# ------------ 5. Claude ãƒ©ãƒƒãƒ‘ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å¤‰æ›´ã—ãªã„ï¼‰ ------------
def judge_risk(text):
    prompt = f"""SNS ç‚ä¸Šãƒªã‚¹ã‚¯ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã—ã¦ãã ã•ã„ã€‚
æœ¬æ–‡ï¼ˆæ—¥æœ¬èªï¼‰ã«ã¤ã„ã¦ã€ç‚ä¸Šã«ã¤ãªãŒã‚‹è¦ç´ ãŒã‚ã‚‹ã‹å³æ ¼ã«åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

## åˆ¤å®šåŸºæº–
â–¼ ãƒªã‚¹ã‚¯ï¼šé«˜
1. äººç¨®ãƒ»å›½ç±ãƒ»å®—æ•™ãƒ»æ€§åˆ¥ãƒ»åœ°åŸŸãªã©ã® **å±æ€§å·®åˆ¥**ã€èª¹è¬—ä¸­å‚·ã€è”‘ç§°ã€ãƒ˜ã‚¤ãƒˆè¡¨ç¾
2. å…¬åºè‰¯ä¿—ã«åã™ã‚‹ **é•æ³•è¡Œç‚ºã®åŠ©é•·**ãƒ»æ¨å¥¨ãƒ»è‡ªæ…¢
3. ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãªäº‹ä»¶ãƒ»ç½å®³ãƒ»æ”¿æ²»ãƒ»å®—æ•™ã«é–¢ã™ã‚‹ **ä¸€æ–¹çš„ã¾ãŸã¯æ‰‡å‹•çš„è¡¨ç¾**
4. å€‹äººã‚„ä¼æ¥­ã¸ã® **æ”»æ’ƒçš„ãƒ»æŒ‘ç™ºçš„ãªè¨€åŠ**ã€åèª‰æ¯€æã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æš´éœ²
5. è™å¾…ãƒ»æ®‹è™ãƒ»æ€§çš„æ¾å–ãªã© **ä¸å¿«ãƒ»æš´åŠ›çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„**
â–¼ ãƒªã‚¹ã‚¯ï¼šä½
ä¸Šè¨˜ 1â€“5 ã®ã„ãšã‚Œã«ã‚‚ **è©²å½“ã—ãªã„** å ´åˆã€‚
## å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå³å®ˆï¼‰
- 1 è¡Œç›®ï¼š**ã€Œãƒªã‚¹ã‚¯ï¼šé«˜ã€** ã¾ãŸã¯ **ã€Œãƒªã‚¹ã‚¯ï¼šä½ã€** ã®ã¿
- 2 è¡Œç›®ï¼šåˆ¤å®šç†ç”±ï¼ˆæ¡ä»¶ç•ªå·ã‚’æ˜è¨˜ã™ã‚‹ã¨ãƒ™ã‚¿ãƒ¼ï¼‰
- 3 è¡Œç›®ä»¥é™ã¯ä½•ã‚‚æ›¸ã‹ãªã„
- æ¡ä»¶ã‚’æº€ãŸã›ãªã„å ´åˆã¯ **ã€ŒERRORã€** ã¨ã ã‘æ›¸ã
--- æœ¬æ–‡ ---
{text}"""
    try:
        ans=claude_call(prompt,200)
        risk="é«˜" if "ãƒªã‚¹ã‚¯ï¼šé«˜" in ans else "ä½"
        return risk,ans,("NG" if risk=="é«˜" else "OK")
    except Exception as e:
        return "é«˜",f"[Error] {e}","NG"

def generate_summary(text,max_retry=MAX_RETRY_BASE):
    prompt=f"""ã‚ãªãŸã¯ Xï¼ˆæ—§Twitterï¼‰å‘ã‘ã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
æ²ç¤ºæ¿ã‚¹ãƒ¬ãƒƒãƒ‰æœ¬æ–‡ã‚’èª­ã¿ã€èª­è€…ãŒç¶šãã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ **å‰å‘ãã§é•·ã‚** ã®æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ã‚’ 1 æœ¬ã ã‘ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
### å‡ºåŠ›ä»•æ§˜ï¼ˆå¿…ãšå®ˆã‚‹ï¼‰
1. **ã‚¿ã‚¤ãƒˆãƒ«æœ¬æ–‡ã®ã¿** ã‚’ 1 è¡Œã§å‡ºåŠ›
   - è¡Œé ­ã«ã€Œ-ã€ã€Œâ€“ã€ã€Œãƒ»ã€ãªã©è¨˜å·ã‚’ä»˜ã‘ãªã„
   - æ¥é ­è¾ã€Œã‚¿ã‚¤ãƒˆãƒ«:ã€ã‚„è§£èª¬æ–‡ï¼ˆä¾‹: ã€Œç¦æ­¢èªã‚’å«ã¾ãšï½ã€ã€Œ90æ–‡å­—ä»¥å†…ã§ï½ã€ï¼‰ã‚’ä»˜ã‘ãªã„
   - åŒä¸€ã®æ–‡ã‚’ 2 å›ä»¥ä¸Šç¹°ã‚Šè¿”ã•ãªã„
   - æ”¹è¡Œãƒ»ã‹ãæ‹¬å¼§ãƒ»ç®‡æ¡æ›¸ããƒ»çµµæ–‡å­—ãƒ»è¨˜å·èª¬æ˜ã‚’ä»˜ã‘ãªã„
   - 90 æ–‡å­—ä»¥å†…
2. æœ¬æ–‡å†’é ­ã« **åœ°åãƒ»é§…åãƒ»æ•°å­—** ã„ãšã‚Œã‹ã‚’å…¥ã‚Œã¦ç›®ã‚’å¼•ãæ§‹æˆã«ã™ã‚‹
3. æœ«å°¾ã« **4ã‹ã‚‰7æ–‡å­—ç¨‹åº¦ã® CTA** ã‚’ä»˜ã‘ã‚‹ï¼ˆä¾‹: è©³ã—ãã¯ã“ã¡ã‚‰ğŸ‘‡ã€ç¶šãã¯ã“ã¡ã‚‰ğŸ‘‡ï¼‰
4. ä¸Šè¨˜ã‚’ 1 ã¤ã§ã‚‚æº€ãŸã›ãªã„ã€ã¾ãŸã¯ç¦æ­¢èªã‚’ 1 èªã§ã‚‚å«ã‚€å ´åˆã¯ **NOK** ã¨ã ã‘å‡ºåŠ›ã™ã‚‹
   - NOK ä»¥å¤–ã®æ–‡å­—ã‚’ä¸€åˆ‡æ›¸ã‹ãªã„
### ç¦æ­¢èª
{', '.join(BANNED_WORDS)}
--- æœ¬æ–‡ ---
{text}"""
    for _ in range(max_retry+1):
        try:
            t=claude_call(prompt,80)
        except Exception: time.sleep(2); continue
        if "NOK" in t.upper(): return "NOK"
        t=re.sub(r'\s+',' ',t.strip())
        t=re.sub(r'^\s*ã‚¿ã‚¤ãƒˆãƒ«[:ï¼š]\s*','',t)
        t=re.sub(r'^.*?[ã€Œ"](.*?)[ã€"]$',r'\1',t)
        if contains_banned(BANNED_WORDS,t): time.sleep(1); continue
        if len(t)>MAX_TITLE_LEN: t=t[:MAX_TITLE_LEN].rstrip("ã€,ã€‚. ")+"â€¦"
        return t+CTA
    return "NOK"

# ------------ 6. ãƒ¡ã‚¤ãƒ³ ------------
def main():
    print("â–¶ main() start")

    # 1. ã‚¹ãƒ¬æŠ½å‡º & å·®åˆ†åˆ¤å®š
    threads = fetch_threads()
    print(f"â–¶ å–å¾—ã‚¹ãƒ¬æ•° = {len(threads)}")
    history = load_history()

    diffs = []
    for t in sorted(
        threads,
        key=lambda x: x["count"] - history.get(x["url"], 0),
        reverse=True,
    ):
        if t["url"] not in history:                         # æ–°è¦ã‚¹ãƒ¬ã¯é™¤å¤–
            continue
        if t["count"] - history[t["url"]] <= 0:             # å·®åˆ†ãªã—ã¯é™¤å¤–
            continue
        diffs.append(t)
        if len(diffs) == 25:
            break
    print(f"â–¶ å·®åˆ†å€™è£œ   = {len(diffs)}")

    # 2. ç‚ä¸Šãƒªã‚¹ã‚¯åˆ¤å®š
    candidates, updated = [], {}
    for d in diffs:
        risk, msg, flag = judge_risk(fetch_thread_text(d["url"]))
        candidates.append({**d, "risk": risk, "comment": msg, "flag": flag})
        updated[d["url"]] = d["count"]

    ok = [c for c in candidates if c["flag"] == "OK"][:POST_COUNT]
    random.shuffle(ok)
    print(f"â–¶ OKå€™è£œ     = {len(ok)}")

    # 3. æŠ•ç¨¿å€™è£œã‚·ãƒ¼ãƒˆã‚’æ›´æ–°
    ws_cand = gc.open_by_key(SPREADSHEET_ID).worksheet(CANDIDATE_SHEET)
    ws_cand.clear()
    ws_cand.append_row(
        ["URL", "å·®åˆ†ãƒ¬ã‚¹æ•°", "ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¿ã‚¤ãƒˆãƒ«", "ç‚ä¸Šãƒªã‚¹ã‚¯", "ã‚³ãƒ¡ãƒ³ãƒˆ", "æŠ•ç¨¿å¯å¦"]
    )
    for c in sorted(
        candidates,
        key=lambda x: x["count"] - history.get(x["url"], 0),
        reverse=True,
    ):
        ws_cand.append_row(
            [
                c["url"],
                c["count"] - history.get(c["url"], 0),
                c["title"],
                c["risk"],
                c["comment"],
                c["flag"],
            ]
        )
    print(f"â–¶ æŠ•ç¨¿å€™è£œã‚·ãƒ¼ãƒˆæ›´æ–° = {len(candidates)} è¡Œ")

    # 4. æŠ•ç¨¿äºˆå®šã‚·ãƒ¼ãƒˆï¼ˆæœ€å¤§ 14 è¡Œãƒ»7 æ—¥å‡ç­‰é…ç½®ï¼‰
    ws_post = gc.open_by_key(SPREADSHEET_ID).worksheet(POST_SHEET)
    ws_post.clear()
    ws_post.append_row(["æ—¥ä»˜", "æŠ•ç¨¿æ™‚é–“", "æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆ", "æŠ•ç¨¿æ¸ˆã¿", "URL"])

    today = datetime.date.today()
    base_monday = today + datetime.timedelta(days=((7 - today.weekday()) % 7 or 7))

    scheduled, row_count = set(), 0
    for c in ok:
        if c["url"] in scheduled:
            continue

        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆNOK ãƒªãƒˆãƒ©ã‚¤ï¼‰
        title = "NOK"
        for _ in range(MAX_EXTRA_RETRY + 1):
            title = generate_summary(fetch_thread_text(c["url"]))
            if title.upper() != "NOK":
                break
        if title.upper() == "NOK":
            continue

        # 7 æ—¥ Ã— 2 æ ã«å‡ç­‰é…ç½®
        day_offset = row_count % 7
        post_date = base_monday + datetime.timedelta(days=day_offset)
        time_str = "8:00" if row_count // 7 == 0 else "15:00"

        # æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        tid = re.search(r"/thread/(\d+)/", c["url"]).group(1)
        utm = f"?utm_source=x&utm_medium=em-{tid}&utm_campaign={post_date:%Y%m%d}"
        post_txt = f"{title}\n#ãƒãƒ³ã‚·ãƒ§ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£\n{c['url']}{utm}"

        ws_post.append_row(
            [
                post_date.strftime("%Y/%m/%d"),
                time_str,
                post_txt,
                "FALSE",
                c["url"],
            ]
        )
        scheduled.add(c["url"])
        row_count += 1
        if row_count == POST_COUNT:          # 14 è¡Œã§çµ‚äº†
            break
    print(f"â–¶ æŠ•ç¨¿è¡Œæ•°   = {row_count}")

    # 5. å±¥æ­´æ›´æ–°
    if os.getenv("TEST_MODE") != "1":
        save_history({**history, **{u: updated[u] for u in scheduled}})

    print("â–¶ Done")

# ------------ 7. å®Ÿè¡Œ ------------
if __name__=="__main__":
    main()
